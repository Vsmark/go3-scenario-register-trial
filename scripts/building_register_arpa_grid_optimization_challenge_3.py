# -*- coding: utf-8 -*-
"""Building Register: ARPA Grid Optimization Challenge 3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15zNqCM5Ndk9i9PwuGztzgJ4-efa8k5Ln

### This is the final file with descripiton register
"""

import json
import pandas as pd

def analyze_scenario(json_path, scenario_name):
    with open(json_path, 'r') as f:
        data = json.load(f)

    ts = data['time_series_input']['general']
    duration = sum(ts['interval_duration'])
    time_steps = ts['time_periods']

    buses = data['network']['bus']
    ac_lines = data['network']['ac_line']
    transformers = data['network']['two_winding_transformer']
    devices = data['network']['simple_dispatchable_device']
    contingencies = data['reliability']['contingency']

    generators = [d for d in devices if d['device_type'] == 'producer']
    loads = [d for d in devices if d['device_type'] == 'consumer']
    total_p_load = sum(d['initial_status']['p'] for d in loads)
    total_q_load = sum(d['initial_status']['q'] for d in loads)
    total_p_gen = sum(d['initial_status']['p'] for d in generators)
    vm_range = [f"{b['uid']}={b['initial_status']['vm']} pu" for b in buses]
    voltage_summary = ", ".join(vm_range)

    grid_size = (
        "Small" if len(buses) <= 3 else
        "Medium" if len(buses) <= 10 else
        "Large"
    )

    # Check if any energy_req or startup constraints exceed horizon
    HET = duration
    TOL = 1e-6
    status = "Valid"
    for d in devices:
        for field in ['energy_req_lb', 'energy_req_ub', 'startups_ub']:
            if field in d:
                for entry in d[field]:
                    if entry[1] > HET + TOL:
                        status = "Invalid"
                        break

    desc = (
        f"This is a {grid_size} grid with {len(buses)} buses and a planning horizon of {duration:.1f} hours. "
        f"It has {len(generators)} producers and {len(loads)} consumers. "
        f"Total initial active load is {total_p_load:.3f} pu and reactive load is {total_q_load:.3f} pu. "
        f"The generators produce {total_p_gen:.3f} pu initially. "
        f"There are {len(ac_lines)} AC lines, {len(transformers)} transformers, and {len(contingencies)} contingency cases. "
    )

    return {
        "Scenario": scenario_name,
        "Folder": subfolder,
        "Duration (h)": duration,
        "Time Steps": time_steps,
        "Buses": len(buses),
        "Generators": len(generators),
        "Loads": len(loads),
        "AC Lines": len(ac_lines),
        "Transformers": len(transformers),
        "Contingencies": len(contingencies),
        "Total Load (pu)": total_p_load,
        "Total Generation (pu)": total_p_gen,
        # "Voltage Magnitudes": voltage_summary,
        "Grid Size": grid_size,
        "Status": status,
        "Description": desc
    }

import os
import re

# Define the root directory where D1, D2, D3 folders exist.
root_dir = "/content/drive/MyDrive/E1"

scenarios = []

# Loop through all 'D' folders dynamically.
for d_folder in ["D1", "D2", "D3"]:
    d_folder_path = os.path.join(root_dir, d_folder)

    # Ensure the directory exists.
    if not os.path.exists(d_folder_path):
        continue

    # Loop through each subfolder inside the D folders.
    for subfolder in os.listdir(d_folder_path):
        subfolder_path = os.path.join(d_folder_path, subfolder)

        # Ensure it's a valid directory.
        if not os.path.isdir(subfolder_path):
            continue

        # Loop through files inside each subfolder.
        for file in os.listdir(subfolder_path):
            # Check if the file matches the scenario naming pattern.
            match = re.match(r"scenario_(\d{3})\.json$", file)  # Match only `scenario_XXX.json`and solutions logs and jsons are kept out
            if match:
                file_path = os.path.join(subfolder_path, file)

                # Try processing the scenario JSON file, skip if not found.
                try:
                    result = analyze_scenario(file_path, file)
                    scenarios.append(result)
                except FileNotFoundError:
                    continue

# Build DataFrame

df = pd.DataFrame(scenarios)
df.sort_values(by=["Buses", "Duration (h)"], inplace=True)
df.set_index("Scenario", inplace=True)

display(df)

df.to_excel("scenario_register.xlsx", index=True)

import json
import pandas as pd

def analyze_and_display(json_path, scenario_name="My Scenario"):
    try:
        with open(json_path, 'r') as f:
            data = json.load(f)
    except FileNotFoundError:
        print(f"❌ File not found: {json_path}")
        return
    except json.JSONDecodeError:
        print(f"❌ Failed to parse JSON: {json_path}")
        return

    # Extract key elements
    ts = data['time_series_input']['general']
    duration = sum(ts['interval_duration'])
    time_steps = ts['time_periods']

    buses = data['network']['bus']
    ac_lines = data['network']['ac_line']
    transformers = data['network']['two_winding_transformer']
    devices = data['network']['simple_dispatchable_device']
    contingencies = data['reliability']['contingency']

    generators = [d for d in devices if d['device_type'] == 'producer']
    loads = [d for d in devices if d['device_type'] == 'consumer']
    total_p_load = sum(d['initial_status']['p'] for d in loads)
    total_q_load = sum(d['initial_status']['q'] for d in loads)
    total_p_gen = sum(d['initial_status']['p'] for d in generators)

    grid_size = (
        "Small" if len(buses) <= 3 else
        "Medium" if len(buses) <= 10 else
        "Large"
    )

    status = "Valid"
    HET = duration
    TOL = 1e-6
    for d in devices:
        for field in ['energy_req_lb', 'energy_req_ub', 'startups_ub']:
            if field in d:
                for entry in d[field]:
                    if entry[1] > HET + TOL:
                        status = "Invalid"
                        break

    desc = (
        f"This is a {grid_size} grid with {len(buses)} buses and a planning horizon of {duration:.1f} hours. "
        f"It has {len(generators)} producers and {len(loads)} consumers. "
        f"Total initial active load is {total_p_load:.3f} pu and reactive load is {total_q_load:.3f} pu. "
        f"The generators produce {total_p_gen:.3f} pu initially. "
        f"There are {len(ac_lines)} AC lines, {len(transformers)} transformers, and {len(contingencies)} contingency cases."
    )

    # Build a one-row dataframe
    result = {
        "Scenario": scenario_name,
        "Folder": subfolder,
        "Duration (h)": duration,
        "Time Steps": time_steps,
        "Buses": len(buses),
        "Generators": len(generators),
        "Loads": len(loads),
        "AC Lines": len(ac_lines),
        "Transformers": len(transformers),
        "Contingencies": len(contingencies),
        "Total Load (pu)": total_p_load,
        "Total Generation (pu)": total_p_gen,
        "Grid Size": grid_size,
        "Status": status,
        "Description": desc
    }

    df = pd.DataFrame([result])
    df.set_index("Scenario", inplace=True)

    print(f"✅ Summary for: {scenario_name}\n")
    display(df)

    return df

# Provide your file path and scenario name
my_scenario = analyze_and_display("/content/drive/MyDrive/E1/D1/C3E1N00003D1/scenario_112.json", "Scenario 112")





# import json
# import pandas as pd

# def analyze_scenario(json_path, scenario_name):
#     with open(json_path, 'r') as f:
#         data = json.load(f)

#     ts = data['time_series_input']['general']
#     duration = sum(ts['interval_duration'])
#     time_steps = ts['time_periods']

#     buses = data['network']['bus']
#     ac_lines = data['network']['ac_line']
#     transformers = data['network']['two_winding_transformer']
#     devices = data['network']['simple_dispatchable_device']
#     contingencies = data['reliability']['contingency']

#     generators = [d for d in devices if d['device_type'] == 'producer']
#     loads = [d for d in devices if d['device_type'] == 'consumer']
#     total_p_load = sum(d['initial_status']['p'] for d in loads)
#     total_q_load = sum(d['initial_status']['q'] for d in loads)
#     total_p_gen = sum(d['initial_status']['p'] for d in generators)
#     vm_range = [f"{b['uid']}={b['initial_status']['vm']} pu" for b in buses]
#     voltage_summary = ", ".join(vm_range)

#     grid_size = (
#         "Small" if len(buses) <= 3 else
#         "Medium" if len(buses) <= 10 else
#         "Large"
#     )

#     # Check if any energy_req or startup constraints exceed horizon
#     HET = duration
#     TOL = 1e-6
#     status = "Valid"
#     for d in devices:
#         for field in ['energy_req_lb', 'energy_req_ub', 'startups_ub']:
#             if field in d:
#                 for entry in d[field]:
#                     if entry[1] > HET + TOL:
#                         status = "Invalid"
#                         break

#     desc = (
#         f"This is a {grid_size} grid with {len(buses)} buses and a planning horizon of {duration:.1f} hours. "
#         f"It has {len(generators)} producers and {len(loads)} consumers. "
#         f"Total initial active load is {total_p_load:.3f} pu and reactive load is {total_q_load:.3f} pu. "
#         f"The generators produce {total_p_gen:.3f} pu initially. "
#         f"There are {len(ac_lines)} AC lines, {len(transformers)} transformers, and {len(contingencies)} contingency cases. "
#         f"Voltage magnitudes: {voltage_summary}."
#     )

#     return {
#         "Scenario": scenario_name,
#         "Duration (h)": duration,
#         "Time Steps": time_steps,
#         "# Buses": len(buses),
#         "# Generators": len(generators),
#         "# Loads": len(loads),
#         "# AC Lines": len(ac_lines),
#         "# Transformers": len(transformers),
#         "# Contingencies": len(contingencies),
#         "Total Load (pu)": total_p_load,
#         "Total Generation (pu)": total_p_gen,
#         "Voltage Magnitudes": voltage_summary,
#         "Grid Size": grid_size,
#         "Status": status,
#         "Description": desc
#     }

# # Run for scenarios 112 and ... (can put more)
# scenarios = []
# for sid in [112]:
#     path = f'/content/drive/MyDrive/E1/D1/C3E1N00003D1/scenario_{sid}.json' #Path for the scenario file comes here
#     try:
#         result = analyze_scenario(path, f"Scenario {sid}")
#         scenarios.append(result)
#     except FileNotFoundError:
#         scenarios.append({"Scenario": f"Scenario {sid}", "Status": "Missing File"})

# # Build DataFrame
# df = pd.DataFrame(scenarios)
# df.set_index("Scenario", inplace=True)

# display(df)

"""### Next plan is to set up a zip file that anyone can access offline and to build a github repo too, so its online and offline and could be run simulataneously"""

